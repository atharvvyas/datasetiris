# @title Default title text
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import GridSearchCV
from sklearn.preprocessing import LabelEncoder



# Load the iris dataset
data = pd.read_csv('/content/Iris (1).csv')
# Print the first few rows of the dataset to inspect the data
print("First few rows of the dataset:")
print(data.head())


# Split the data into training and test sets
X = data.drop('Species', axis=1)
y = data['Species']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

 #Create a label encoder for the target labels
label_encoder = LabelEncoder()

# Encode the target labels (species) into numerical values
y_train_encoded = label_encoder.fit_transform(y_train)
y_test_encoded = label_encoder.transform(y_test)

# Reshape the encoded labels to 2D arrays
y_train_encoded = y_train_encoded.reshape(-1, 1)
y_test_encoded = y_test_encoded.reshape(-1, 1)

# Create an SVM classifier
svm_classifier = SVC(kernel='linear')


# Train the classifier on the training data
svm_classifier.fit(X_train, y_train_encoded)


# Make predictions on the test data
y_pred_encoded = svm_classifier.predict(X_test)

# Scale the data
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Define a function to evaluate the model
def evaluate_model(model, X_test, y_test):

    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    classification_rep = classification_report(y_test, y_pred)

    return accuracy, classification_rep


# Train the SVM classifier
svm_classifier = SVC(kernel='linear')
svm_classifier.fit(X_train, y_train)


# Evaluate the trained model
accuracy, classification_rep = evaluate_model(svm_classifier, X_test, y_test)

# Print the evaluation results
print(f"Accuracy: {accuracy:.2f}")
print("Classification Report:")
print(classification_rep)

# Perform hyperparameter tuning to improve the model performance
param_grid = {
    'C': [0.1, 1, 10, 100],
    'gamma': ['auto', 'scale', 0.001, 0.01, 0.1, 1]
}

grid_search = GridSearchCV(svm_classifier, param_grid, cv=5, n_jobs=-1)
grid_search.fit(X_train, y_train)

# Get the best model from the grid search
best_model = grid_search.best_estimator_

# Evaluate the best model on the test set
accuracy, classification_rep = evaluate_model(best_model, X_test, y_test)

# Print the evaluation results of the best model
print("Best Model Evaluation Results:")
print(f"Accuracy: {accuracy:.2f}")
print("Classification Report:")
print(classification_rep)
# Print the actual vs. predicted labels for the test set (first 10 samples)
print("\nActual vs. Predicted Labels (first 10 samples):")
for actual, predicted in zip(y_test_encoded[:10], y_pred_encoded[:10]):
    print(f"Actual: {label_encoder.classes_[actual]}, Predicted: {label_encoder.classes_[predicted]}")

